#!/usr/bin/env python3
"""
üîß Script d'Installation Automatique - Classificateur d'Humour pour Commits
=======================================================================

Ce script d√©tecte automatiquement votre configuration hardware et installe
les d√©pendances appropri√©es pour le classificateur d'humour.

Usage:
    python install.py
    python install.py --force-cpu  # Force l'installation CPU m√™me si GPU d√©tect√©
    python install.py --gpu-only   # Force l'installation GPU (√©choue si pas de GPU)

Auteur: Assistant IA
Version: 1.0
"""

import os
import sys
import subprocess
import platform
import argparse
from pathlib import Path

def print_header():
    """Affiche l'en-t√™te du script"""
    print("\n" + "="*70)
    print("ü§ñ INSTALLATION - CLASSIFICATEUR D'HUMOUR POUR COMMITS")
    print("="*70)
    print("üîç D√©tection automatique du hardware...\n")

def detect_gpu():
    """D√©tecte la pr√©sence d'un GPU NVIDIA compatible CUDA"""
    try:
        # V√©rifier si nvidia-smi est disponible
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ GPU NVIDIA d√©tect√©")
            print(f"   üìä Informations GPU:")
            # Extraire les infos basiques du GPU
            lines = result.stdout.split('\n')
            for line in lines:
                if 'NVIDIA' in line and 'Driver Version' in line:
                    print(f"   {line.strip()}")
                    break
            return True
        else:
            print("‚ùå Aucun GPU NVIDIA d√©tect√©")
            return False
    except FileNotFoundError:
        print("‚ùå nvidia-smi non trouv√© - Aucun GPU NVIDIA d√©tect√©")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors de la d√©tection GPU: {e}")
        return False

def detect_system_info():
    """D√©tecte les informations syst√®me"""
    print(f"üíª Syst√®me: {platform.system()} {platform.release()}")
    print(f"üêç Python: {sys.version.split()[0]}")
    print(f"üèóÔ∏è  Architecture: {platform.machine()}")
    
    # V√©rifier la version de Python
    if sys.version_info < (3, 7):
        print("‚ùå Python 3.7+ requis")
        return False
    else:
        print("‚úÖ Version Python compatible")
    
    return True

def install_package(package, description=""):
    """Installe un package avec pip"""
    try:
        print(f"üì¶ Installation de {package}...")
        if description:
            print(f"   üìù {description}")
        
        result = subprocess.run(
            [sys.executable, "-m", "pip", "install", package],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print(f"‚úÖ {package} install√© avec succ√®s")
            return True
        else:
            print(f"‚ùå Erreur lors de l'installation de {package}")
            print(f"   D√©tails: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur lors de l'installation de {package}: {e}")
        return False

def check_package_installed(package):
    """V√©rifie si un package est d√©j√† install√©"""
    try:
        __import__(package.replace("-", "_"))
        return True
    except ImportError:
        return False

def install_base_dependencies(force_cpu=True):
    """Installe les d√©pendances de base"""
    print("\nüîß Installation des d√©pendances de base...")

    base_packages = [
        ("transformers", "Biblioth√®que Hugging Face Transformers"),
        ("huggingface_hub", "Client Hugging Face Hub"),
        ("datasets", "Gestion des datasets"),
        ("safetensors", "Format de sauvegarde s√©curis√©"),
        ("numpy", "Calculs num√©riques"),
        ("requests", "Requ√™tes HTTP")
    ]

    # N'installer accelerate que si force_cpu n'est pas activ√©
    if not force_cpu:
        base_packages.insert(3, ("accelerate", "Acc√©l√©ration des mod√®les"))

    success = True
    for package, description in base_packages:
        if check_package_installed(package):
            print(f"‚úÖ {package} d√©j√† install√©")
        else:
            if not install_package(package, description):
                success = False

    return success

def install_pytorch_gpu():
    """Installe PyTorch avec support GPU"""
    print("\nüöÄ Installation de PyTorch avec support GPU...")
    
    # PyTorch avec CUDA (version stable)
    pytorch_gpu_cmd = "torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
    
    try:
        print("üì¶ Installation de PyTorch GPU (CUDA 12.1)...")
        result = subprocess.run(
            [sys.executable, "-m", "pip", "install"] + pytorch_gpu_cmd.split(),
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print("‚úÖ PyTorch GPU install√© avec succ√®s")
            return True
        else:
            print("‚ùå Erreur lors de l'installation de PyTorch GPU")
            print("üîÑ Tentative d'installation CPU...")
            return install_pytorch_cpu()
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        print("üîÑ Tentative d'installation CPU...")
        return install_pytorch_cpu()

def install_pytorch_cpu():
    """Installe PyTorch version CPU uniquement"""
    print("\nüíª Installation de PyTorch version CPU...")
    
    pytorch_cpu_cmd = "torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
    
    try:
        print("üì¶ Installation de PyTorch CPU...")
        result = subprocess.run(
            [sys.executable, "-m", "pip", "install"] + pytorch_cpu_cmd.split(),
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print("‚úÖ PyTorch CPU install√© avec succ√®s")
            return True
        else:
            print("‚ùå Erreur lors de l'installation de PyTorch CPU")
            print(f"   D√©tails: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False

def test_installation():
    """Teste l'installation en important les modules principaux"""
    print("\nüß™ Test de l'installation...")
    
    try:
        import torch
        print(f"‚úÖ PyTorch {torch.__version__} import√©")
        
        # Test GPU si disponible
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA disponible - {torch.cuda.device_count()} GPU(s) d√©tect√©(s)")
            print(f"   üìä GPU actuel: {torch.cuda.get_device_name(0)}")
        else:
            print("üíª Mode CPU (pas de GPU CUDA disponible)")
        
        import transformers
        print(f"‚úÖ Transformers {transformers.__version__} import√©")
        
        from huggingface_hub import __version__ as hf_version
        print(f"‚úÖ Hugging Face Hub {hf_version} import√©")
        
        print("\nüéâ Installation r√©ussie !")
        return True
        
    except ImportError as e:
        print(f"‚ùå Erreur d'importation: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Erreur lors du test: {e}")
        return False



def main():
    """Fonction principale"""
    parser = argparse.ArgumentParser(description="Installation automatique du classificateur d'humour")
    parser.add_argument("--force-cpu", action="store_true", help="Force l'installation CPU")
    parser.add_argument("--gpu-only", action="store_true", help="Force l'installation GPU")
    parser.add_argument("--skip-test", action="store_true", help="Ignore les tests d'installation")
    
    args = parser.parse_args()
    
    print_header()
    
    # D√©tection du syst√®me
    if not detect_system_info():
        print("‚ùå Syst√®me non compatible")
        sys.exit(1)
    
    print()
    
    # D√©tection GPU
    has_gpu = detect_gpu() and not args.force_cpu
    
    if args.gpu_only and not has_gpu:
        print("‚ùå --gpu-only sp√©cifi√© mais aucun GPU d√©tect√©")
        sys.exit(1)
    
    print()
    
    # Installation des d√©pendances de base
    if not install_base_dependencies(args.force_cpu):
        print("‚ùå √âchec de l'installation des d√©pendances de base")
        sys.exit(1)
    
    # Installation de PyTorch
    if has_gpu or args.gpu_only:
        pytorch_success = install_pytorch_gpu()
    else:
        pytorch_success = install_pytorch_cpu()
    
    if not pytorch_success:
        print("‚ùå √âchec de l'installation de PyTorch")
        sys.exit(1)
    
    # Test de l'installation
    if not args.skip_test:
        if not test_installation():
            print("‚ùå Les tests d'installation ont √©chou√©")
            sys.exit(1)
    
    print("\n" + "="*70)
    print("üéâ INSTALLATION TERMIN√âE AVEC SUCC√àS !")
    print("="*70)
    print("\nüìñ √âtapes suivantes:")
    print("   1. Configurez la variable d'environnement COMMITS_JSON:")
    print("      Windows: set COMMITS_JSON=chemin/vers/votre/fichier.json")
    print("      Linux/Mac: export COMMITS_JSON=chemin/vers/votre/fichier.json")
    print("   2. Installez Flask: pip install flask")
    print("   3. Lancez l'interface web: python web_app.py")
    print("   4. Ouvrez http://localhost:5000 dans votre navigateur")
    print("\nüí° Le mod√®le sera t√©l√©charg√© automatiquement au premier usage (~420MB)")
    print("\nüìö Consultez README.md pour plus d'informations")

if __name__ == "__main__":
    main()