#!/usr/bin/env python3
"""
Script de refusion LoRA pour le classifieur d'humour de commits

Ce script permet de fusionner facilement un nouveau mod√®le LoRA entra√Æn√©
avec le mod√®le de base EuroBERT pour cr√©er un nouveau mod√®le complet.

Usage:
    python refusion_lora.py --lora_path chemin/vers/modele_lora [--output_path nouveau_modele]

Exemple:
    python refusion_lora.py --lora_path ../eurobert_peft_v4 --output_path eurobert_full_v2
"""

import argparse
import os
import sys
import shutil
from pathlib import Path

try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    from peft import PeftModel
except ImportError as e:
    print(f"‚ùå Erreur d'importation : {e}")
    print("Assurez-vous d'avoir install√© les d√©pendances avec : pip install -r requirements.txt")
    sys.exit(1)

def check_lora_model(lora_path):
    """V√©rifie que le mod√®le LoRA existe et est valide"""
    if not os.path.exists(lora_path):
        print(f"‚ùå Le chemin {lora_path} n'existe pas")
        return False
    
    # V√©rifier la pr√©sence des fichiers essentiels
    required_files = ['adapter_config.json', 'adapter_model.safetensors']
    for file in required_files:
        if not os.path.exists(os.path.join(lora_path, file)):
            print(f"‚ùå Fichier manquant : {file}")
            return False
    
    print(f"‚úÖ Mod√®le LoRA trouv√© : {lora_path}")
    return True

def fuse_lora_model(lora_path, output_path, base_model="jplu/eurobert-base-cased"):
    """Fusionne le mod√®le LoRA avec le mod√®le de base"""
    print(f"\nüîÑ D√©but de la fusion LoRA...")
    print(f"   ‚Ä¢ Mod√®le de base : {base_model}")
    print(f"   ‚Ä¢ Mod√®le LoRA : {lora_path}")
    print(f"   ‚Ä¢ Sortie : {output_path}")
    
    try:
        # Charger le mod√®le de base
        print("\nüì• Chargement du mod√®le de base...")
        base_model_obj = AutoModelForSequenceClassification.from_pretrained(
            base_model, 
            num_labels=2,
            trust_remote_code=True
        )
        
        # Charger le tokenizer
        print("üî§ Chargement du tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)
        
        # Charger le mod√®le LoRA
        print("üîß Chargement du mod√®le LoRA...")
        peft_model = PeftModel.from_pretrained(base_model_obj, lora_path)
        
        # Fusionner les mod√®les
        print("‚öôÔ∏è Fusion en cours...")
        merged_model = peft_model.merge_and_unload()
        
        # Sauvegarder le mod√®le fusionn√©
        print(f"üíæ Sauvegarde vers {output_path}...")
        os.makedirs(output_path, exist_ok=True)
        merged_model.save_pretrained(output_path)
        tokenizer.save_pretrained(output_path)
        
        print(f"‚úÖ Fusion termin√©e avec succ√®s !")
        print(f"   Nouveau mod√®le disponible dans : {output_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la fusion : {e}")
        return False

def backup_current_model(current_path):
    """Cr√©e une sauvegarde du mod√®le actuel"""
    if os.path.exists(current_path):
        backup_path = f"{current_path}_backup"
        counter = 1
        while os.path.exists(backup_path):
            backup_path = f"{current_path}_backup_{counter}"
            counter += 1
        
        print(f"üì¶ Sauvegarde du mod√®le actuel : {backup_path}")
        shutil.copytree(current_path, backup_path)
        return backup_path
    return None

def main():
    parser = argparse.ArgumentParser(
        description="Refusion d'un mod√®le LoRA avec EuroBERT pour le classifieur d'humour"
    )
    parser.add_argument(
        "--lora_path", 
        required=True, 
        help="Chemin vers le mod√®le LoRA √† fusionner"
    )
    parser.add_argument(
        "--output_path", 
        default="eurobert_full_new",
        help="Chemin de sortie pour le mod√®le fusionn√© (d√©faut: eurobert_full_new)"
    )
    parser.add_argument(
        "--base_model",
        default="jplu/eurobert-base-cased",
        help="Mod√®le de base √† utiliser (d√©faut: jplu/eurobert-base-cased)"
    )
    parser.add_argument(
        "--replace_current",
        action="store_true",
        help="Remplace le mod√®le actuel (eurobert_full) par le nouveau"
    )
    parser.add_argument(
        "--backup",
        action="store_true",
        help="Cr√©e une sauvegarde du mod√®le actuel avant remplacement"
    )
    
    args = parser.parse_args()
    
    print("üîÑ Script de refusion LoRA")
    print("=" * 50)
    
    # V√©rifier le mod√®le LoRA
    if not check_lora_model(args.lora_path):
        sys.exit(1)
    
    # Fusionner le mod√®le
    if not fuse_lora_model(args.lora_path, args.output_path, args.base_model):
        sys.exit(1)
    
    # Gestion du remplacement
    if args.replace_current:
        current_model_path = "eurobert_full"
        
        if args.backup:
            backup_path = backup_current_model(current_model_path)
            if backup_path:
                print(f"‚úÖ Sauvegarde cr√©√©e : {backup_path}")
        
        if os.path.exists(current_model_path):
            print(f"üîÑ Remplacement de {current_model_path}...")
            shutil.rmtree(current_model_path)
        
        shutil.move(args.output_path, current_model_path)
        print(f"‚úÖ Mod√®le remplac√© avec succ√®s !")
        print(f"   Le nouveau mod√®le est maintenant dans : {current_model_path}")
    
    print("\nüéâ Processus termin√© avec succ√®s !")
    print(f"   Vous pouvez maintenant utiliser le nouveau mod√®le avec :")
    print(f"   python commit_humor_classifier.py --text 'votre message de test'")

if __name__ == "__main__":
    main()